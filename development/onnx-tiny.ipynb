{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c71f26e-b399-4570-90e0-502c8d809e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2d37f5-dbd5-4799-a52e-d80e5f9c8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install coloredlogs onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe713ee-d456-4ac4-8370-a70a88281283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.embeddings import TransformerWordEmbeddings, TransformerDocumentEmbeddings\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.data import Corpus, Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5306d8b-f5a4-4f08-a4d9-bf062168deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier.load(\"models/rubert_1731798298/model_epoch_3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ab3a95-7bd6-484e-93f0-da33c935f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(model.embeddings, (TransformerWordEmbeddings, TransformerDocumentEmbeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932f4e12-72b5-4b9a-8b9c-1cb37ffebfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-16 23:40:57,371 Reading data from flair_data\n",
      "2024-11-16 23:40:57,373 Train: flair_data/train.csv\n",
      "2024-11-16 23:40:57,375 Dev: flair_data/dev.csv\n",
      "2024-11-16 23:40:57,376 Test: flair_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "column_name_map = {0: \"text\", 1: \"label\"}\n",
    "corpus: Corpus = CSVClassificationCorpus(\"flair_data\",\n",
    "                                            column_name_map,\n",
    "                                            skip_header=False,\n",
    "                                            delimiter='\\t',    # tab-separated files\n",
    "                                            label_type='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db21c8ce-4961-484d-8961-81f549c8543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(corpus.test)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866c5e3e-4814-4201-96b6-711d2b8c72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/63 [00:07<02:30,  2.51s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(corpus.test, verbose=True, mini_batch_size=8, gold_label_type='label') # 2 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26755c7-54ad-48c8-8c5b-873975f96488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings = model.embeddings.export_onnx(\"embeddings-rubert-base.onnx\", test[:10], providers=[\"CPUExecutionProvider\"], session_options={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e17ea6e-4f93-4f5a-8dbf-41160f9db383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_onnx.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fb44cd-723c-4621-ae52-0c50f0096462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier.load(\"model_onnx.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8823a5-bb67-4551-abbe-52ae2d5d2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 18/63 [00:05<00:14,  3.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_label_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flair/nn/model.py:297\u001b[0m, in \u001b[0;36mClassifier.evaluate\u001b[0;34m(self, data_points, gold_label_type, out_path, embedding_storage_mode, mini_batch_size, main_evaluation_metric, exclude_labels, gold_label_dictionary, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     datapoint\u001b[38;5;241m.\u001b[39mremove_labels(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# predict for batch\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m loss_and_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_storage_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_storage_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmini_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_loss:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_and_count, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flair/nn/model.py:858\u001b[0m, in \u001b[0;36mDefaultClassifier.predict\u001b[0;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# pass data points through network and decode\u001b[39;00m\n\u001b[1;32m    857\u001b[0m data_point_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_data_points(batch, data_points)\n\u001b[0;32m--> 858\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_point_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_scores(scores, data_points)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# if anything could possibly be predicted\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = model.evaluate(corpus.test, verbose=True, mini_batch_size=8, gold_label_type='label') # 3 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1487dca-209a-4e85-95c4-19a1856fcf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "model.embeddings.quantize_model(\n",
    "            \"embeddings-rubert-base-optimized-8bit.onnx\",  extra_options={\"DisableShapeInference\": True}, use_external_data_format=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad31769a-b188-42a9-aa54-e05a88a517ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error Unknown Provider Type: GPUExecutionProvider when using ['CPUExecutionProvider', 'GPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "model.embeddings.remove_session()\n",
    "model.embeddings.onnx_model = \"embeddings-rubert-base-optimized-8bit.onnx\"\n",
    "model.embeddings.providers = [\"CPUExecutionProvider\", \"GPUExecutionProvider\"] # updated providers config\n",
    "model.embeddings.create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180eecf7-125c-4099-b726-79ade7c4a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 22/63 [00:06<00:12,  3.18it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(corpus.test, verbose=True, mini_batch_size=8, gold_label_type='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7095b5-2b17-4a01-aee0-44d18ec44ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "- F-score (micro) 0.998\n",
      "- F-score (macro) 0.9988\n",
      "- Accuracy 0.998\n",
      "\n",
      "By class:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "NON_FOOD_GOODS     1.0000    0.9896    0.9948        96\n",
      "    FOOD_GOODS     1.0000    1.0000    1.0000        90\n",
      "       SERVICE     0.9888    1.0000    0.9944        88\n",
      "  BANK_SERVICE     1.0000    1.0000    1.0000        49\n",
      "           TAX     1.0000    1.0000    1.0000        48\n",
      "          LOAN     1.0000    1.0000    1.0000        41\n",
      "       LEASING     1.0000    1.0000    1.0000        38\n",
      "   REALE_STATE     1.0000    1.0000    1.0000        27\n",
      "NOT_CLASSIFIED     1.0000    1.0000    1.0000        23\n",
      "\n",
      "      accuracy                         0.9980       500\n",
      "     macro avg     0.9988    0.9988    0.9988       500\n",
      "  weighted avg     0.9980    0.9980    0.9980       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d7d0a35-feb7-4d3d-ba0c-1e07b929aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba745e60-bcd4-4840-9b7b-94d55a4e1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346f4cea-bb62-468f-9f9f-39f242df9c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 16/63 [00:04<00:14,  3.30it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(corpus.test, verbose=True, mini_batch_size=8, gold_label_type='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b24ae-4c72-4ed1-b74d-77adeb9530b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings.onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1729f-85c6-44ea-bfb5-89d419032406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
